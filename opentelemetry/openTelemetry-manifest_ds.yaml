apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: oteld
  labels:
    app: opentelemetry
    app.kubernetes.io/component: oteld-daemonset
spec:
  mode: daemonset
  serviceAccount: otelcontribcol
  image: otel/opentelemetry-collector-contrib:0.101.0
  ports:
    - name: prometheus
      port: 9090
      targetPort: 9090
  args:
    feature-gates: "telemetry.useOtelWithSDKConfigurationForInternalTelemetry"
  env:
    - name: CLUSTER_ID
      valueFrom:
        secretKeyRef:
          name: dynatrace
          key: clusterid
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: DT_ENDPOINT
      valueFrom:
        secretKeyRef:
          name: dynatrace
          key: dynatrace_oltp_url
    - name: DT_API_TOKEN
      valueFrom:
        secretKeyRef:
          name: dynatrace
          key: dt_api_token
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: CLUSTERNAME
      valueFrom:
        secretKeyRef:
          name: dynatrace
          key: clustername
    - name: OTEL_SERVICE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.labels['app.kubernetes.io/component']
    - name: OTEL_RESOURCE_ATTRIBUTES
      value: service.name=$(OTEL_SERVICE_NAME)
  volumeMounts:
    - mountPath: /var/log
      name: varlog
      readOnly: true
    - mountPath: /var/lib/docker/containers
      name: varlibdockercontainers
      readOnly: true
  volumes:
    - name: varlog
      hostPath:
        path: /var/log
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
  config:
    receivers:
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 5s
            static_configs:
            - targets:
              - ${MY_POD_IP}:8888
      otlp:
        protocols:
          grpc: { }
          http: { }

      filelog:
        include:
          - /var/log/pods/*/*/*.log
        start_at: beginning
        include_file_path: true
        include_file_name: false
        operators:
          # Find out which format is used by kubernetes
          - type: router
            id: get-format
            routes:
              - output: parser-docker
                expr: 'body matches "^\\{"'
              - output: parser-crio
                expr: 'body matches "^[^ Z]+ "'
              - output: parser-containerd
                expr: 'body matches "^[^ Z]+Z"'
          # Parse CRI-O format
          - type: regex_parser
            id: parser-crio
            regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout_type: gotime
              layout: '2006-01-02T15:04:05.999999999Z07:00'
          # Parse CRI-Containerd format
          - type: regex_parser
            id: parser-containerd
            regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          # Parse Docker format
          - type: json_parser
            id: parser-docker
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          - type: move
            from: attributes.log
            to: body
          # Extract metadata from file path
          - type: regex_parser
            id: extract_metadata_from_filepath
            regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
            parse_from: attributes["log.file.path"]
            cache:
              size: 128  # default maximum amount of Pods per Node is 110
          # Rename attributes
          - type: move
            from: attributes.stream
            to: attributes["log.iostream"]
          - type: move
            from: attributes.container_name
            to: resource["k8s.container.name"]
          - type: move
            from: attributes.namespace
            to: resource["k8s.namespace.name"]
          - type: move
            from: attributes.pod_name
            to: resource["k8s.pod.name"]
          - type: move
            from: attributes.restart_count
            to: resource["k8s.container.restart_count"]
          - type: move
            from: attributes.uid
            to: resource["k8s.pod.uid"]
    
    


    processors:
      batch:
        send_batch_max_size: 1000
        timeout: 30s
        send_batch_size : 800
    
    
     
      cumulativetodelta: {}
    
      filter:
        error_mode: ignore
        metrics:
          metric:
            - 'type == METRIC_DATA_TYPE_HISTOGRAM'
    
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
    
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.cluster.uid
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.name
            - from: resource_attribute
              name: k8s.namespace.name
          # Pod labels which can be fetched via K8sattributeprocessor
      memory_limiter:
        check_interval: 1s
        limit_percentage: 70
        spike_limit_percentage: 30
      
      resource:
        attributes:
        - key: k8s.cluster.name 
          value: ${CLUSTERNAME}
          action: insert
      transform/audit:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              - merge_maps(cache,ParseJSON(attributes["log"]), "upsert") where attributes["log"] != nil
              - set(attributes["opa.message"],cache["msg"]) where cache["msg"] != nil
              - set(attributes["opa.constraint.kind"],cache["constraint_kind"]) where cache["constraint_kind"] != nil
              - set(attributes["opa.constraint.name"],cache["constraintName"]) where cache["constraintName"] != nil
              - set(attributes["opa.event.type"],cache["event_type"]) where cache["event_type"] != nil
              - set(attributes["opa.audit.id"],cache["audit_id"]) where cache["audit_id"] != nil
              - set(attributes["opa.constraint.action"],cache["constraint_action"]) where cache["constraint_action"]!=nil
              - set(attributes["opa.request.user"], cache["request_username"]) where cache["request_username"] != nil
              - set(attributes["opa.process"], cache["process"]) where cache["process"] != nil
              - set(attributes["opa.resource.kind"], cache["resource_kind"]) where cache["resource_kind"] != nil
              - set(attributes["opa.resource.name"], cache["resource_name"]) where cache["resource_name"] != nil
              - set(attributes["opa.resource.namespace"], cache["resource_namespace"]) where cache["resource_namespace"] != nil
              - set(attributes["opa.process"], cache["process"]) where cache["process"] != nil
              - set(attributes["opa.timestamp"], cache["ts"]) where cache["ts"] != nil
      transform:
        error_mode: ignore
        log_statements:
          - context: resource
            statements:
              - set(attributes["dt.kubernetes.workload.kind"], "statefulset") where IsString(attributes["k8s.statefulset.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.statefulset.name"]) where IsString(attributes["k8s.statefulset.name"])
              - set(attributes["dt.kubernetes.workload.kind"], "deployment") where IsString(attributes["k8s.deployment.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.deployment.name"]) where IsString(attributes["k8s.deployment.name"])
              - set(attributes["dt.kubernetes.workload.kind"], "daemonset") where IsString(attributes["k8s.daemonset.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.daemonset.name"]) where IsString(attributes["k8s.daemonset.name"])
              - set(attributes["dt.kubernetes.cluster.id"], attributes["k8s.cluster.uid"]) where IsString(attributes["k8s.cluster.uid"])
    
        metric_statements:
          - context: resource
            statements:
              - set(attributes["dt.kubernetes.workload.kind"], "statefulset") where IsString(attributes["k8s.statefulset.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.statefulset.name"]) where IsString(attributes["k8s.statefulset.name"])
              - set(attributes["dt.kubernetes.workload.kind"], "deployment") where IsString(attributes["k8s.deployment.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.deployment.name"]) where IsString(attributes["k8s.deployment.name"])
              - set(attributes["dt.kubernetes.workload.kind"], "daemonset") where IsString(attributes["k8s.daemonset.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.daemonset.name"]) where IsString(attributes["k8s.daemonset.name"])
              - set(attributes["dt.kubernetes.cluster.id"], attributes["k8s.cluster.uid"]) where IsString(attributes["k8s.cluster.uid"])
        trace_statements:
          - context: resource
            statements:
              - set(attributes["dt.kubernetes.workload.kind"], "statefulset") where IsString(attributes["k8s.statefulset.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.statefulset.name"]) where IsString(attributes["k8s.statefulset.name"])
              - set(attributes["dt.kubernetes.workload.kind"], "deployment") where IsString(attributes["k8s.deployment.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.deployment.name"]) where IsString(attributes["k8s.deployment.name"])
              - set(attributes["dt.kubernetes.workload.kind"], "daemonset") where IsString(attributes["k8s.daemonset.name"])
              - set(attributes["dt.kubernetes.workload.name"], attributes["k8s.daemonset.name"]) where IsString(attributes["k8s.daemonset.name"])
              - set(attributes["dt.kubernetes.cluster.id"], attributes["k8s.cluster.uid"]) where IsString(attributes["k8s.cluster.uid"])



    connectors:

      routing/log:
        default_pipelines: [ logs/default ]
        error_mode: ignore
        table:
          - statement: route() where attributes["k8s.namespace.name"] == "gatekeeper"
            pipelines: [ logs/audit ]
    exporters:
      logging:
        verbosity: detailed
     
      otlphttp:
        endpoint: ${DT_ENDPOINT}/api/v2/otlp
        headers:
          Authorization: "Api-Token ${DT_API_TOKEN}"
      
    
    
    service:
      pipelines:
        logs/audit:
          receivers: [ routing/log ]
          processors: [ transform/audit,k8sattributes,transform,resource,batch ]
          exporters: [ otlphttp ]
        logs/default:
          receivers: [ routing/log ]
          processors: [ k8sattributes,transform,resource,batch ]
          exporters: [ otlphttp ]
        logs:
          receivers: [filelog]
          processors: [memory_limiter]
          exporters: [ routing/log]
        metrics:
          receivers: [prometheus]
          processors: [memory_limiter,filter,k8sattributes,transform,resource,cumulativetodelta,batch]
          exporters: [otlphttp]
        traces:
          receivers: [ otlp ]
          processors: [ memory_limiter,k8sattributes,transform,batch ]
          exporters: [ otlphttp ]
      telemetry:
        metrics:
          address: ${MY_POD_IP}:8888
        traces:
          processors:
            - batch:
                exporter:
                  otlp:
                    protocol: grpc/protobuf
                    endpoint: http://localhost:4317
